{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133737"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CMU WORDLIST\n",
    "import nltk\n",
    "ntries=nltk.corpus.cmudict.entries()\n",
    "len(ntries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', ['AH0']),\n",
       " ('a.', ['EY1']),\n",
       " ('a', ['EY1']),\n",
       " ('a42128',\n",
       "  ['EY1',\n",
       "   'F',\n",
       "   'AO1',\n",
       "   'R',\n",
       "   'T',\n",
       "   'UW1',\n",
       "   'W',\n",
       "   'AH1',\n",
       "   'N',\n",
       "   'T',\n",
       "   'UW1',\n",
       "   'EY1',\n",
       "   'T']),\n",
       " ('aaa', ['T', 'R', 'IH2', 'P', 'AH0', 'L', 'EY1']),\n",
       " ('aaberg', ['AA1', 'B', 'ER0', 'G']),\n",
       " ('aachen', ['AA1', 'K', 'AH0', 'N']),\n",
       " ('aachener', ['AA1', 'K', 'AH0', 'N', 'ER0']),\n",
       " ('aaker', ['AA1', 'K', 'ER0']),\n",
       " ('aalseth', ['AA1', 'L', 'S', 'EH0', 'TH']),\n",
       " ('aamodt', ['AA1', 'M', 'AH0', 'T']),\n",
       " ('aancor', ['AA1', 'N', 'K', 'AO2', 'R']),\n",
       " ('aardema', ['AA0', 'R', 'D', 'EH1', 'M', 'AH0']),\n",
       " ('aardvark', ['AA1', 'R', 'D', 'V', 'AA2', 'R', 'K']),\n",
       " ('aaron', ['EH1', 'R', 'AH0', 'N']),\n",
       " (\"aaron's\", ['EH1', 'R', 'AH0', 'N', 'Z']),\n",
       " ('aarons', ['EH1', 'R', 'AH0', 'N', 'Z']),\n",
       " ('aaronson', ['EH1', 'R', 'AH0', 'N', 'S', 'AH0', 'N']),\n",
       " ('aaronson', ['AA1', 'R', 'AH0', 'N', 'S', 'AH0', 'N']),\n",
       " (\"aaronson's\", ['EH1', 'R', 'AH0', 'N', 'S', 'AH0', 'N', 'Z']),\n",
       " (\"aaronson's\", ['AA1', 'R', 'AH0', 'N', 'S', 'AH0', 'N', 'Z']),\n",
       " ('aarti', ['AA1', 'R', 'T', 'IY2']),\n",
       " ('aase', ['AA1', 'S']),\n",
       " ('aasen', ['AA1', 'S', 'AH0', 'N']),\n",
       " ('ab', ['AE1', 'B']),\n",
       " ('ab', ['EY1', 'B', 'IY1']),\n",
       " ('ababa', ['AH0', 'B', 'AA1', 'B', 'AH0']),\n",
       " ('ababa', ['AA1', 'B', 'AH0', 'B', 'AH0']),\n",
       " ('abacha', ['AE1', 'B', 'AH0', 'K', 'AH0']),\n",
       " ('aback', ['AH0', 'B', 'AE1', 'K']),\n",
       " ('abaco', ['AE1', 'B', 'AH0', 'K', 'OW2']),\n",
       " ('abacus', ['AE1', 'B', 'AH0', 'K', 'AH0', 'S']),\n",
       " ('abad', ['AH0', 'B', 'AA1', 'D']),\n",
       " ('abadaka', ['AH0', 'B', 'AE1', 'D', 'AH0', 'K', 'AH0']),\n",
       " ('abadi', ['AH0', 'B', 'AE1', 'D', 'IY0']),\n",
       " ('abadie', ['AH0', 'B', 'AE1', 'D', 'IY0']),\n",
       " ('abair', ['AH0', 'B', 'EH1', 'R']),\n",
       " ('abalkin', ['AH0', 'B', 'AA1', 'L', 'K', 'IH0', 'N']),\n",
       " ('abalone', ['AE2', 'B', 'AH0', 'L', 'OW1', 'N', 'IY0']),\n",
       " ('abalos', ['AA0', 'B', 'AA1', 'L', 'OW0', 'Z']),\n",
       " ('abandon', ['AH0', 'B', 'AE1', 'N', 'D', 'AH0', 'N']),\n",
       " ('abandoned', ['AH0', 'B', 'AE1', 'N', 'D', 'AH0', 'N', 'D']),\n",
       " ('abandoning', ['AH0', 'B', 'AE1', 'N', 'D', 'AH0', 'N', 'IH0', 'NG']),\n",
       " ('abandonment',\n",
       "  ['AH0', 'B', 'AE1', 'N', 'D', 'AH0', 'N', 'M', 'AH0', 'N', 'T']),\n",
       " ('abandonments',\n",
       "  ['AH0', 'B', 'AE1', 'N', 'D', 'AH0', 'N', 'M', 'AH0', 'N', 'T', 'S']),\n",
       " ('abandons', ['AH0', 'B', 'AE1', 'N', 'D', 'AH0', 'N', 'Z']),\n",
       " ('abanto', ['AH0', 'B', 'AE1', 'N', 'T', 'OW0']),\n",
       " ('abarca', ['AH0', 'B', 'AA1', 'R', 'K', 'AH0']),\n",
       " ('abare', ['AA0', 'B', 'AA1', 'R', 'IY0']),\n",
       " ('abascal', ['AE1', 'B', 'AH0', 'S', 'K', 'AH0', 'L']),\n",
       " ('abash', ['AH0', 'B', 'AE1', 'SH']),\n",
       " ('abashed', ['AH0', 'B', 'AE1', 'SH', 'T']),\n",
       " ('abate', ['AH0', 'B', 'EY1', 'T']),\n",
       " ('abated', ['AH0', 'B', 'EY1', 'T', 'IH0', 'D']),\n",
       " ('abatement', ['AH0', 'B', 'EY1', 'T', 'M', 'AH0', 'N', 'T']),\n",
       " ('abatements', ['AH0', 'B', 'EY1', 'T', 'M', 'AH0', 'N', 'T', 'S']),\n",
       " ('abates', ['AH0', 'B', 'EY1', 'T', 'S']),\n",
       " ('abating', ['AH0', 'B', 'EY1', 'T', 'IH0', 'NG']),\n",
       " ('abba', ['AE1', 'B', 'AH0']),\n",
       " ('abbado', ['AH0', 'B', 'AA1', 'D', 'OW0']),\n",
       " ('abbas', ['AH0', 'B', 'AA1', 'S']),\n",
       " ('abbasi', ['AA0', 'B', 'AA1', 'S', 'IY0']),\n",
       " ('abbate', ['AA1', 'B', 'EY0', 'T']),\n",
       " ('abbatiello', ['AA0', 'B', 'AA0', 'T', 'IY0', 'EH1', 'L', 'OW0']),\n",
       " ('abbe', ['AE1', 'B', 'IY0']),\n",
       " ('abbe', ['AE0', 'B', 'EY1']),\n",
       " ('abbenhaus', ['AE1', 'B', 'AH0', 'N', 'HH', 'AW2', 'S']),\n",
       " ('abbett', ['AH0', 'B', 'EH1', 'T']),\n",
       " ('abbeville', ['AE1', 'B', 'V', 'IH0', 'L']),\n",
       " ('abbey', ['AE1', 'B', 'IY0']),\n",
       " (\"abbey's\", ['AE1', 'B', 'IY0', 'Z']),\n",
       " ('abbie', ['AE1', 'B', 'IY0']),\n",
       " ('abbitt', ['AE1', 'B', 'IH0', 'T']),\n",
       " ('abbot', ['AE1', 'B', 'AH0', 'T']),\n",
       " ('abbotstown', ['AE1', 'B', 'AH0', 'T', 'S', 'T', 'AW1', 'N']),\n",
       " ('abbott', ['AE1', 'B', 'AH0', 'T']),\n",
       " (\"abbott's\", ['AE1', 'B', 'AH0', 'T', 'S']),\n",
       " ('abbottstown', ['AE1', 'B', 'AH0', 'T', 'S', 'T', 'AW1', 'N']),\n",
       " ('abboud', ['AH0', 'B', 'UW1', 'D']),\n",
       " ('abboud', ['AH0', 'B', 'AW1', 'D']),\n",
       " ('abbreviate', ['AH0', 'B', 'R', 'IY1', 'V', 'IY0', 'EY2', 'T']),\n",
       " ('abbreviated', ['AH0', 'B', 'R', 'IY1', 'V', 'IY0', 'EY2', 'T', 'AH0', 'D']),\n",
       " ('abbreviated', ['AH0', 'B', 'R', 'IY1', 'V', 'IY0', 'EY2', 'T', 'IH0', 'D']),\n",
       " ('abbreviates', ['AH0', 'B', 'R', 'IY1', 'V', 'IY0', 'EY2', 'T', 'S']),\n",
       " ('abbreviating',\n",
       "  ['AH0', 'B', 'R', 'IY1', 'V', 'IY0', 'EY2', 'T', 'IH0', 'NG']),\n",
       " ('abbreviation',\n",
       "  ['AH0', 'B', 'R', 'IY2', 'V', 'IY0', 'EY1', 'SH', 'AH0', 'N']),\n",
       " ('abbreviations',\n",
       "  ['AH0', 'B', 'R', 'IY2', 'V', 'IY0', 'EY1', 'SH', 'AH0', 'N', 'Z']),\n",
       " ('abbruzzese', ['AA0', 'B', 'R', 'UW0', 'T', 'S', 'EY1', 'Z', 'IY0']),\n",
       " ('abbs', ['AE1', 'B', 'Z']),\n",
       " ('abby', ['AE1', 'B', 'IY0']),\n",
       " ('abco', ['AE1', 'B', 'K', 'OW0']),\n",
       " ('abcotek', ['AE1', 'B', 'K', 'OW0', 'T', 'EH2', 'K']),\n",
       " ('abdalla', ['AE2', 'B', 'D', 'AE1', 'L', 'AH0']),\n",
       " ('abdallah', ['AE2', 'B', 'D', 'AE1', 'L', 'AH0']),\n",
       " ('abdel', ['AE1', 'B', 'D', 'EH2', 'L']),\n",
       " ('abdella', ['AE2', 'B', 'D', 'EH1', 'L', 'AH0']),\n",
       " ('abdicate', ['AE1', 'B', 'D', 'AH0', 'K', 'EY2', 'T']),\n",
       " ('abdicated', ['AE1', 'B', 'D', 'AH0', 'K', 'EY2', 'T', 'AH0', 'D']),\n",
       " ('abdicates', ['AE1', 'B', 'D', 'AH0', 'K', 'EY2', 'T', 'S']),\n",
       " ('abdicating', ['AE1', 'B', 'D', 'IH0', 'K', 'EY2', 'T', 'IH0', 'NG'])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntries[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('machine.n.01'),\n",
       " Synset('machine.n.02'),\n",
       " Synset('machine.n.03'),\n",
       " Synset('machine.n.04'),\n",
       " Synset('machine.n.05'),\n",
       " Synset('car.n.01'),\n",
       " Synset('machine.v.01'),\n",
       " Synset('machine.v.02')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.wordnet\n",
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('machine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#atask 2-sample text classifier\n",
    "def gender_features(word):\n",
    "    return{'last_letter':word[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'a'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features('Obama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')]+\n",
    "[(name, 'female') for name in names.words('female.txt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets=[(gender_features(n),gender) for (n,gender) in labeled_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,test_set=featuresets[500:],featuresets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "classifier=nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('keerthana'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Nithin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Lakshmi'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'female'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(gender_features('Dinesh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier,test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectoriser and cosine siilarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect=CountVectorizer(binary=True)\n",
    "corpus = [\"Bugatti is all about French-style luxury and exceptional vehicles, but it’s a brand that stands for innovative technology, too  \", \" Bugatti is in fact continuing a long-standing tradition here: the company founder Ettore Bugatti himself developed unique vehicles using groundbreaking technologies\"]\n",
    "vect.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about:0\n",
      "all:1\n",
      "and:2\n",
      "brand:3\n",
      "bugatti:4\n",
      "but:5\n",
      "company:6\n",
      "continuing:7\n",
      "developed:8\n",
      "ettore:9\n",
      "exceptional:10\n",
      "fact:11\n",
      "for:12\n",
      "founder:13\n",
      "french:14\n",
      "groundbreaking:15\n",
      "here:16\n",
      "himself:17\n",
      "in:18\n",
      "innovative:19\n",
      "is:20\n",
      "it:21\n",
      "long:22\n",
      "luxury:23\n",
      "standing:24\n",
      "stands:25\n",
      "style:26\n",
      "technologies:27\n",
      "technology:28\n",
      "that:29\n",
      "the:30\n",
      "too:31\n",
      "tradition:32\n",
      "unique:33\n",
      "using:34\n",
      "vehicles:35\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(vocab.keys()):\n",
    "    print(\"{}:{}\".format(key, vocab[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(vect.transform([\"Bugatti is all about French-style luxury and exceptional vehicles, but it’s a brand that stands for innovative technology, too \"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 0 1]\n",
      " [0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(vect.transform(corpus).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(vect.transform([\"LiFi is a wireless optical networking technology that uses LEDs for data transmission\"]).toarray(), vect.transform([\" LiFi is considered to be as a light-based WiFi which uses light instead of radio waves to transmit information.\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
